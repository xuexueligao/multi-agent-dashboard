{
  "version": 3,
  "sources": ["../../../src/values/size.ts"],
  "sourcesContent": ["/**\n * Calculate the size of a Convex value in bytes.\n *\n * This matches the Rust implementation in crates/value/src/ which is used\n * to compute bandwidth and document size limits.\n *\n * Size formula by type:\n * - Null: 1 byte (type marker)\n * - Boolean: 1 byte (type marker, value stored in marker)\n * - Int64 (bigint): 9 bytes (1 type marker + 8 bytes for 64-bit value)\n * - Float64 (number): 9 bytes (1 type marker + 8 bytes for 64-bit value)\n * - String: 2 + string.length bytes (1 type marker + UTF-8 bytes + 1 null terminator)\n * - Bytes (ArrayBuffer): 2 + bytes.length bytes (1 type marker + bytes + 1 terminator)\n * - Array: 2 + sum(element sizes) bytes (1 type marker + elements + 1 terminator)\n * - Object: 2 + sum(field_name.length + 1 + value.size) bytes\n *           (1 type marker + (field_name + null terminator + value)* + 1 terminator)\n *\n * For documents with system fields (_id and _creationTime), the size includes:\n * - _id field: 4 bytes (field name + null) + string size (2 + 31+ chars)\n * - _creationTime field: 14 bytes (field name + null) + 9 bytes (Float64)\n *\n * @module\n */\n\nimport type { Value } from \"./value.js\";\nimport { isSimpleObject } from \"../common/index.js\";\n\n/**\n * Calculate the size in bytes of a Convex value.\n *\n * This matches how Convex calculates document size for bandwidth tracking\n * and size limit enforcement.\n *\n * @param value - A Convex value to measure\n * @returns The size in bytes\n *\n * @public\n */\nexport function getConvexSize(value: Value): number {\n  if (value === null) {\n    return 1;\n  }\n  if (typeof value === \"boolean\") {\n    return 1;\n  }\n  if (typeof value === \"bigint\") {\n    // Int64: 1 byte type marker + 8 bytes value\n    return 9;\n  }\n  if (typeof value === \"number\") {\n    // Float64: 1 byte type marker + 8 bytes value\n    return 9;\n  }\n  if (typeof value === \"string\") {\n    // String: 1 byte type marker + UTF-8 bytes + 1 byte null terminator\n    // Use TextEncoder to get the actual UTF-8 byte length\n    return 2 + getUtf8ByteLength(value);\n  }\n  if (value instanceof ArrayBuffer) {\n    // Bytes: 1 byte type marker + byte array length + 1 byte terminator\n    return 2 + value.byteLength;\n  }\n  if (Array.isArray(value)) {\n    // Array: 1 byte type marker + sum of element sizes + 1 byte terminator\n    let size = 2; // marker + terminator\n    for (const element of value) {\n      size += getConvexSize(element);\n    }\n    return size;\n  }\n  if (isSimpleObject(value)) {\n    // Object: 1 byte type marker + sum(field_name + null + value) + 1 byte terminator\n    let size = 2; // marker + terminator\n    for (const [key, val] of Object.entries(value)) {\n      if (val !== undefined) {\n        // field name length + null terminator + value size\n        size += getUtf8ByteLength(key) + 1 + getConvexSize(val);\n      }\n    }\n    return size;\n  }\n\n  throw new Error(`Unsupported value type: ${typeof value}`);\n}\n\n/**\n * Threshold above which we use TextEncoder instead of manual counting.\n * For short strings, the JS loop is ~15x faster due to avoiding allocation.\n * For long strings (500+ chars), TextEncoder's native implementation wins.\n */\nconst UTF8_LENGTH_THRESHOLD = 500;\n\n/**\n * Get the UTF-8 byte length of a string.\n *\n * For short strings, counts bytes directly from UTF-16 code units to avoid allocation.\n * For long strings, uses native TextEncoder which is faster despite allocation.\n *\n * @internal\n */\nfunction getUtf8ByteLength(str: string): number {\n  // For long strings, native TextEncoder is faster despite allocation\n  if (str.length > UTF8_LENGTH_THRESHOLD) {\n    return new TextEncoder().encode(str).length;\n  }\n\n  // For short strings, avoid allocation overhead with manual counting\n  let bytes = 0;\n  for (let i = 0; i < str.length; i++) {\n    const code = str.charCodeAt(i);\n    if (code < 0x80) {\n      // ASCII: 1 byte\n      bytes += 1;\n    } else if (code < 0x800) {\n      // 2-byte UTF-8\n      bytes += 2;\n    } else if (code >= 0xd800 && code <= 0xdbff) {\n      // High surrogate - part of a surrogate pair encoding a code point >= U+10000\n      // These are encoded as 4 bytes in UTF-8\n      bytes += 4;\n      i++; // Skip the low surrogate\n    } else {\n      // 3-byte UTF-8 (includes low surrogates if encountered alone, which is invalid but handled)\n      bytes += 3;\n    }\n  }\n  return bytes;\n}\n\n// Note: The exact _id size varies based on the table number:\n// - Tables 1-127: 31 char ID\n// - Tables 128-16383: 32 char ID\n// We use 32 chars as a typical value (tables 128-16383).\nexport const SYSTEM_FIELD_ID_ESTIMATE = 38;\n// _creationTime: field name (14) + Float64 (9)\nexport const SYSTEM_FIELD_CREATION_TIME_SIZE = 23;\n\n/**\n * Calculate the size of a document including system fields.\n *\n * If your value already has _id and _creationTime fields, this will count them\n * in the normal size calculation. Otherwise, it adds the constant overhead\n * for system fields.\n *\n * @param value - A Convex object (document body)\n * @param options - Options for size calculation\n * @returns The size in bytes\n *\n * @public\n */\nexport function getDocumentSize(\n  value: Record<string, Value>,\n  options?: {\n    /**\n     * @internal\n     * Length of the _id field if it is missing. Defaults to standard length.\n     */\n    customIdLength?: number;\n  },\n): number {\n  const baseSize = getConvexSize(value);\n\n  // Check if system fields are already present\n  const hasId = \"_id\" in value && value[\"_id\"] !== undefined;\n  const hasCreationTime =\n    \"_creationTime\" in value && value[\"_creationTime\"] !== undefined;\n\n  if (hasId && hasCreationTime) {\n    return baseSize;\n  }\n\n  // Add size for missing system fields\n  let additionalSize = 0;\n\n  if (!hasId) {\n    if (options?.customIdLength) {\n      // 4 bytes for _id field name + 2 bytes for string overhead.\n      additionalSize += options.customIdLength + 6;\n    } else {\n      additionalSize += SYSTEM_FIELD_ID_ESTIMATE;\n    }\n  }\n\n  if (!hasCreationTime) {\n    additionalSize += SYSTEM_FIELD_CREATION_TIME_SIZE;\n  }\n\n  // The base size includes 2 bytes for object markers, but we need to account\n  // for adding new fields to an existing object structure\n  return baseSize + additionalSize;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAyBA,oBAA+B;AAaxB,SAAS,cAAc,OAAsB;AAClD,MAAI,UAAU,MAAM;AAClB,WAAO;AAAA,EACT;AACA,MAAI,OAAO,UAAU,WAAW;AAC9B,WAAO;AAAA,EACT;AACA,MAAI,OAAO,UAAU,UAAU;AAE7B,WAAO;AAAA,EACT;AACA,MAAI,OAAO,UAAU,UAAU;AAE7B,WAAO;AAAA,EACT;AACA,MAAI,OAAO,UAAU,UAAU;AAG7B,WAAO,IAAI,kBAAkB,KAAK;AAAA,EACpC;AACA,MAAI,iBAAiB,aAAa;AAEhC,WAAO,IAAI,MAAM;AAAA,EACnB;AACA,MAAI,MAAM,QAAQ,KAAK,GAAG;AAExB,QAAI,OAAO;AACX,eAAW,WAAW,OAAO;AAC3B,cAAQ,cAAc,OAAO;AAAA,IAC/B;AACA,WAAO;AAAA,EACT;AACA,UAAI,8BAAe,KAAK,GAAG;AAEzB,QAAI,OAAO;AACX,eAAW,CAAC,KAAK,GAAG,KAAK,OAAO,QAAQ,KAAK,GAAG;AAC9C,UAAI,QAAQ,QAAW;AAErB,gBAAQ,kBAAkB,GAAG,IAAI,IAAI,cAAc,GAAG;AAAA,MACxD;AAAA,IACF;AACA,WAAO;AAAA,EACT;AAEA,QAAM,IAAI,MAAM,2BAA2B,OAAO,KAAK,EAAE;AAC3D;AAOA,MAAM,wBAAwB;AAU9B,SAAS,kBAAkB,KAAqB;AAE9C,MAAI,IAAI,SAAS,uBAAuB;AACtC,WAAO,IAAI,YAAY,EAAE,OAAO,GAAG,EAAE;AAAA,EACvC;AAGA,MAAI,QAAQ;AACZ,WAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACnC,UAAM,OAAO,IAAI,WAAW,CAAC;AAC7B,QAAI,OAAO,KAAM;AAEf,eAAS;AAAA,IACX,WAAW,OAAO,MAAO;AAEvB,eAAS;AAAA,IACX,WAAW,QAAQ,SAAU,QAAQ,OAAQ;AAG3C,eAAS;AACT;AAAA,IACF,OAAO;AAEL,eAAS;AAAA,IACX;AAAA,EACF;AACA,SAAO;AACT;AAMO,MAAM,2BAA2B;AAEjC,MAAM,kCAAkC;AAexC,SAAS,gBACd,OACA,SAOQ;AACR,QAAM,WAAW,cAAc,KAAK;AAGpC,QAAM,QAAQ,SAAS,SAAS,MAAM,KAAK,MAAM;AACjD,QAAM,kBACJ,mBAAmB,SAAS,MAAM,eAAe,MAAM;AAEzD,MAAI,SAAS,iBAAiB;AAC5B,WAAO;AAAA,EACT;AAGA,MAAI,iBAAiB;AAErB,MAAI,CAAC,OAAO;AACV,QAAI,SAAS,gBAAgB;AAE3B,wBAAkB,QAAQ,iBAAiB;AAAA,IAC7C,OAAO;AACL,wBAAkB;AAAA,IACpB;AAAA,EACF;AAEA,MAAI,CAAC,iBAAiB;AACpB,sBAAkB;AAAA,EACpB;AAIA,SAAO,WAAW;AACpB;",
  "names": []
}
